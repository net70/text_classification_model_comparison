{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bba0b6-c1c0-4d7c-80ec-7fb4bb0306bb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c7db18-e429-429e-af2e-d490475c08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.environ.get('base_path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71246ef-f4a9-43bc-aa46-69efbfe287b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "from models.GPT_4.openai_utils import get_gpt_tokens\n",
    "from models.GPT_4.openai_utils import get_batch_completion_tasks\n",
    "from models.GPT_4.openai_utils import generate_jsonl_file\n",
    "from models.GPT_4.openai_utils import upload_file_to_openai\n",
    "from models.GPT_4.openai_utils import create_batch_completion_job\n",
    "from models.GPT_4.openai_utils import get_batch_job_status\n",
    "from models.GPT_4.openai_utils import get_batch_job_results\n",
    "from models.GPT_4.openai_utils import save_batch_results_to_jsonl\n",
    "from models.GPT_4.openai_utils import map_jsonl_batch_completion_results_to_df\n",
    "from models.GPT_4.openai_utils import generate_openai_fine_tuning_json_from_df\n",
    "from models.GPT_4.openai_utils import upload_fine_tuning_file_to_openai\n",
    "from models.GPT_4.openai_utils import fine_tune_gpt_model\n",
    "from models.GPT_4.openai_utils import check_fine_tuning_job_status\n",
    "from models.GPT_4.openai_utils import get_fine_tuned_model_details\n",
    "\n",
    "from utils.dataframe_utils import read_pandas_csv_clean_columns_names\n",
    "from utils.dataframe_utils import get_model_cross_validation\n",
    "\n",
    "from utils.text_utils import remove_pii\n",
    "from utils.text_utils import lang_code_to_nltk\n",
    "from utils.text_utils import iso_639_1_code_language_map\n",
    "\n",
    "from utils.utils import find_file\n",
    "\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ef44d291-1ff4-4575-aba5-2a333330e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathaniel.maymon/Downloads/Share_to_drive/text_classification_model_comparison/utils/checkpoint_data/checkpoint_sales_files_embedding.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset_path = find_file('checkpoint_sales_files_embedding.pkl')\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "042deffd-5337-463d-abc7-2f978c87674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sql_sql_name', 'contact_us_form_description', 'target', 'status',\n",
      "       'sales_type', 'ft', 'input_pii_removed', 'text_len',\n",
      "       'language_iso639_1', 'language', 'nltk_tokenized', 'num_tokens',\n",
      "       'embeddings', 'bert_based_embeddings', 'xlm_roberta_embeddings'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sql_sql_name</th>\n",
       "      <th>contact_us_form_description</th>\n",
       "      <th>target</th>\n",
       "      <th>status</th>\n",
       "      <th>sales_type</th>\n",
       "      <th>ft</th>\n",
       "      <th>input_pii_removed</th>\n",
       "      <th>text_len</th>\n",
       "      <th>language_iso639_1</th>\n",
       "      <th>language</th>\n",
       "      <th>nltk_tokenized</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>bert_based_embeddings</th>\n",
       "      <th>xlm_roberta_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-270959</td>\n",
       "      <td>Looking for an individual plan</td>\n",
       "      <td>support</td>\n",
       "      <td>Qualified</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking for an individual plan</td>\n",
       "      <td>30</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>[individual, plan]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.38701433, 0.1578661, -0.16941527, -0.29124...</td>\n",
       "      <td>[0.20684707, 0.16516663, 0.45383996, 0.274494,...</td>\n",
       "      <td>[-0.021906804, -0.02679788, 0.08908692, -0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-270963</td>\n",
       "      <td>I'd like to know if you integrate with Talisma...</td>\n",
       "      <td>sales</td>\n",
       "      <td>Qualified</td>\n",
       "      <td>Scale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'd like to know if you integrate with Talisma...</td>\n",
       "      <td>116</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>[integrate, talisman, crm, set, asap]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.5965658, -0.43355212, 0.19410376, -0.11731...</td>\n",
       "      <td>[0.047534026, -0.11715461, -0.16869079, 0.0983...</td>\n",
       "      <td>[-0.031946268, -0.018111331, 0.1367632, 0.0195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-270966</td>\n",
       "      <td>Hello - would like to learn how Lusha can help...</td>\n",
       "      <td>sales</td>\n",
       "      <td>Unqualified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello - would like to learn how Lusha can help...</td>\n",
       "      <td>133</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>[learn, lusha, sales, team, leverage, sales, n...</td>\n",
       "      <td>9</td>\n",
       "      <td>[-0.15919332, -0.5191771, -0.20935886, -0.5327...</td>\n",
       "      <td>[-0.19207695, -0.061742973, 0.18255222, 0.1014...</td>\n",
       "      <td>[-0.070657, -0.0052590887, 0.22000055, 0.07287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-270968</td>\n",
       "      <td>I want to know all your plans and pricing and ...</td>\n",
       "      <td>sales</td>\n",
       "      <td>Unqualified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to know all your plans and pricing and ...</td>\n",
       "      <td>122</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>[plans, pricing, benefits, monthly, basis, sen...</td>\n",
       "      <td>8</td>\n",
       "      <td>[-0.56908274, -0.34940168, 0.036727045, -0.173...</td>\n",
       "      <td>[0.36898538, -0.025350137, -0.0860117, -0.0582...</td>\n",
       "      <td>[-0.016302777, -0.0058536422, 0.1011779, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-270969</td>\n",
       "      <td>Im trying to make my account but i get the err...</td>\n",
       "      <td>support</td>\n",
       "      <td>Unqualified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Im trying to make my account but i get the err...</td>\n",
       "      <td>150</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>[account, error, code, domain, marked, suspici...</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.14534955, -0.23843925, -0.13587804, 0.1417...</td>\n",
       "      <td>[-0.06293887, -0.43082377, 0.16223387, 0.03430...</td>\n",
       "      <td>[-0.02608389, 0.04559744, 0.29144728, 0.039253...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sql_sql_name                        contact_us_form_description   target  \\\n",
       "0     A-270959                     Looking for an individual plan  support   \n",
       "1     A-270963  I'd like to know if you integrate with Talisma...    sales   \n",
       "2     A-270966  Hello - would like to learn how Lusha can help...    sales   \n",
       "3     A-270968  I want to know all your plans and pricing and ...    sales   \n",
       "4     A-270969  Im trying to make my account but i get the err...  support   \n",
       "\n",
       "        status    sales_type   ft  \\\n",
       "0    Qualified  Self Service  NaN   \n",
       "1    Qualified         Scale  NaN   \n",
       "2  Unqualified           NaN  NaN   \n",
       "3  Unqualified           NaN  NaN   \n",
       "4  Unqualified           NaN  NaN   \n",
       "\n",
       "                                   input_pii_removed  text_len  \\\n",
       "0                     Looking for an individual plan        30   \n",
       "1  I'd like to know if you integrate with Talisma...       116   \n",
       "2  Hello - would like to learn how Lusha can help...       133   \n",
       "3  I want to know all your plans and pricing and ...       122   \n",
       "4  Im trying to make my account but i get the err...       150   \n",
       "\n",
       "  language_iso639_1 language  \\\n",
       "0                en  English   \n",
       "1                en  English   \n",
       "2                en  English   \n",
       "3                en  English   \n",
       "4                en  English   \n",
       "\n",
       "                                      nltk_tokenized  num_tokens  \\\n",
       "0                                 [individual, plan]           2   \n",
       "1              [integrate, talisman, crm, set, asap]           5   \n",
       "2  [learn, lusha, sales, team, leverage, sales, n...           9   \n",
       "3  [plans, pricing, benefits, monthly, basis, sen...           8   \n",
       "4  [account, error, code, domain, marked, suspici...          10   \n",
       "\n",
       "                                          embeddings  \\\n",
       "0  [-0.38701433, 0.1578661, -0.16941527, -0.29124...   \n",
       "1  [-0.5965658, -0.43355212, 0.19410376, -0.11731...   \n",
       "2  [-0.15919332, -0.5191771, -0.20935886, -0.5327...   \n",
       "3  [-0.56908274, -0.34940168, 0.036727045, -0.173...   \n",
       "4  [-0.14534955, -0.23843925, -0.13587804, 0.1417...   \n",
       "\n",
       "                               bert_based_embeddings  \\\n",
       "0  [0.20684707, 0.16516663, 0.45383996, 0.274494,...   \n",
       "1  [0.047534026, -0.11715461, -0.16869079, 0.0983...   \n",
       "2  [-0.19207695, -0.061742973, 0.18255222, 0.1014...   \n",
       "3  [0.36898538, -0.025350137, -0.0860117, -0.0582...   \n",
       "4  [-0.06293887, -0.43082377, 0.16223387, 0.03430...   \n",
       "\n",
       "                              xlm_roberta_embeddings  \n",
       "0  [-0.021906804, -0.02679788, 0.08908692, -0.004...  \n",
       "1  [-0.031946268, -0.018111331, 0.1367632, 0.0195...  \n",
       "2  [-0.070657, -0.0052590887, 0.22000055, 0.07287...  \n",
       "3  [-0.016302777, -0.0058536422, 0.1011779, 0.003...  \n",
       "4  [-0.02608389, 0.04559744, 0.29144728, 0.039253...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(dataset_path)\n",
    "\n",
    "print(df.columns, '\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e9b4e1-6cee-426d-b215-7943dc857723",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f'''You're a sales rep at Lusha, and an expert in classifying incoming prospects.\n",
    "\n",
    "In Lusha, we have prospects that connect by submitting a sales form, and leave notes. Many times through the form notes, it's possible to know how to route the prospect internally.\n",
    "\n",
    "If a prospect wants to follow up on the offer or is genuinely interested, or wants to substantially upgrade their account such as adding multiple users \\ seats e.g “I want to add 3 users to my account” and not “I want to add a user to my account” etc.(as having more than two users can indicate on a potential enterprise lead), or massively increase credits, or asks about meeting or suggests time to meet, or is interested in a proof of concept or a trial, or they inquire about intent\\ technographic \\ job-change filters, Integrations, API features, or ask about\\mention a competitor, it should probably go to the sales team.\n",
    "\n",
    "On the other hand, if the prospect is having an issue with the product (e.g. something not working, bugs, payment issues etc.) or has a general question like \"what's a credit?\" etc., or is asking about a pro\\professional monthly plan, or wants to add one user to their account (e.g. I want to add a user to my account), it's probably more relevant for support.\n",
    "\n",
    "Please note: If the input says something that is entirely irrelevant, or the prospect is trying to promote\\sell\\market\\advertise\\offer-services to us\\you it's irrelevant for our sales and support reps (e.g. \"I'd love to discuss how your team can leverage LinkedIn Navigator and Insights to complement your current efforts and exceed your revenue targets. Would you be available for a quick chat next week?\" etc.) . Same case if the message is a generic system message (e.g. DMARC report, cooking advice, or generally completely off topic.\n",
    "This is true in cases where the form notes don’t provide any additional context or clear intent.\n",
    "\n",
    "Use your best judgment as a sales representative.\n",
    "\n",
    "These are the rules:\n",
    "  - If the prospect's input indicates it's relevant for the sales team, reply: \"sales\"\n",
    "  - If the prospect's input indicates the input is irrelevant, reply: \"irrelevant\"\n",
    "  - If the prospect's input indicates they are trying to promote or market to us, reply: \"support\"\n",
    "  - In any other case, reply: \"support\"\n",
    "\n",
    "Please respond in one word based on the rules provided above. Do not provide an explanation or additional context.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777507a7-77b3-46bc-9d72-8f4c99ee497f",
   "metadata": {},
   "source": [
    "# GPT-4-TURBO Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4e43d-1741-4890-8654-a20532451aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IF( \n",
    "  !ISBLANK({!$Record.Related_SQL__c}) && \n",
    "  OR (\n",
    "     ISNEW(),\n",
    "     AND (\n",
    "       ISCHANGED({!$Record.StageName}),\n",
    "     OR(\n",
    "        ISPICKVAL({!$Record.StageName}, \"Meeting Scheduled\"),\n",
    "        ISPICKVAL({!$Record.StageName}, \"Business Discovery\"),\n",
    "        ISPICKVAL({!$Record.StageName}, \"Closed Won\"),\n",
    "        ISPICKVAL({!$Record.StageName}, \"Closed Lost\"),\n",
    "        ISPICKVAL({!$Record.StageName}, \"Rejected by AE\")\n",
    "        )\n",
    "    )\n",
    ")\n",
    ",TRUE, FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79afbc6d-2612-40b9-a735-5138ef8a4087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8458106098165592,\n",
       " 'f1_macro': 0.7026327563331174,\n",
       " 'f1_micro': 0.8458106098165592,\n",
       " 'f1_weighted': 0.8690878455900922,\n",
       " 'precision_macro': 0.6238348766883687,\n",
       " 'precision_micro': 0.8458106098165592,\n",
       " 'precision_weighted': 0.9235202644615773,\n",
       " 'recall_macro': 0.9049821409246412,\n",
       " 'recall_micro': 0.8458106098165592,\n",
       " 'recall_weighted': 0.8458106098165592}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_cross_validation(df, 'target', 'gpt_decision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc73cb8-79b9-4178-97a4-45f2f3c73b2e",
   "metadata": {},
   "source": [
    "# GPT-4o Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b1b6923-e648-4dda-a424-1f360f083562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-HX25F5lVeWVRs7RD7tijVdc2\n",
      "batch_0yx5NkQZE3eDvHqWe312nAY7\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=None, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2956, failed=0, total=8068), _request_id='req_b8639ddd9a08328620715d570d78d676', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=None, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=5759, failed=0, total=8068), _request_id='req_00c80ee1320a9dc092569f9c18dfd926', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=None, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=7998, failed=0, total=8068), _request_id='req_864d68ba55f9bad154643f13ff85e16b', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=1726936512, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=8068, failed=0, total=8068), _request_id='req_d2abc88b3868f066d2603447a9ba2c31', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=1726936512, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=8068, failed=0, total=8068), _request_id='req_767750139ce80a4a1292cb6f9bda49dd', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=1726936512, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=8068, failed=0, total=8068), _request_id='req_ee29d3f31f0e5ec78849a1ae3d1855a0', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_0yx5NkQZE3eDvHqWe312nAY7', completion_window='24h', created_at=1726935354, endpoint='/v1/chat/completions', input_file_id='file-HX25F5lVeWVRs7RD7tijVdc2', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726937195, error_file_id=None, errors=None, expired_at=None, expires_at=1727021754, failed_at=None, finalizing_at=1726936512, in_progress_at=1726935359, metadata={'description': 'Get GPT-4o model results on test set batch file file-HX25F5lVeWVRs7RD7tijVdc2'}, output_file_id='file-TbxezQgoPVmNmPo9JwkS4all', request_counts=BatchRequestCounts(completed=8068, failed=0, total=8068), _request_id='req_eaf1e938375bf301a87bfcb631870aa3', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new batch processing file on the error set\n",
    "gpt_4o_file_name = 'gpt_4o_test_set'\n",
    "\n",
    "gpt_4o_batch_data = get_batch_completion_tasks(\n",
    "    df=df,\n",
    "    user_prompt_col='input_pii_removed',\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    temperature=0,\n",
    "    system_prompt=system_prompt,\n",
    "    max_tokens=3\n",
    ")\n",
    "\n",
    "generate_jsonl_file(gpt_4o_file_name, gpt_4o_batch_data)\n",
    "\n",
    "# Upload batch set to OpenAI\n",
    "gpt_4o_batch_file_id = upload_file_to_openai(f'{gpt_4o_file_name}.jsonl', 'batch')\n",
    "print(gpt_4o_batch_file_id)\n",
    "\n",
    "# Create Batch Job for Error File\n",
    "gpt_4o_batch_job = create_batch_completion_job(\n",
    "    gpt_4o_batch_file_id,\n",
    "    \"/v1/chat/completions\",\n",
    "    {\"description\": f\"Get GPT-4o model results on test set batch file {gpt_4o_batch_file_id}\"}\n",
    ")\n",
    "gpt_4o_batch_job_id = gpt_4o_batch_job.id\n",
    "print(gpt_4o_batch_job_id)\n",
    "\n",
    "# Monitor Batch job Status\n",
    "batch_job_output_file_id = None\n",
    "batch_error_file_id      = None\n",
    "job_status = None\n",
    "\n",
    "while job_status not in ['completed', 'failed', 'cancelled']:\n",
    "    # Check status every 5 minutes\n",
    "    time.sleep(60*5)\n",
    "    \n",
    "    batch_job_status         = get_batch_job_status(gpt_4o_batch_job_id)\n",
    "    job_status               = batch_job_status.status\n",
    "    batch_job_output_file_id = batch_job_status.output_file_id\n",
    "    batch_error_file_id      = batch_job_status.error_file_id\n",
    "\n",
    "    print(batch_job_status, '\\n')\n",
    "\n",
    "# Save and map results back to original DF. \n",
    "gpt_4o_results_file_name = 'gpt_4o_model_results_records'\n",
    "output_file = get_batch_job_results(batch_job_output_file_id)\n",
    "save_batch_results_to_jsonl(output_file, gpt_4o_results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6fde1971-2eef-4636-aff9-082bb766c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt4o_results'] = None\n",
    "map_jsonl_batch_completion_results_to_df(df, gpt_4o_results_file_name, 'gpt4o_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab677e74-9f36-4900-b9b6-87632c5cf97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6116757560733763,\n",
       " 'f1_macro': 0.47808285418673085,\n",
       " 'f1_micro': 0.6116757560733763,\n",
       " 'f1_weighted': 0.6859130636798886,\n",
       " 'precision_macro': 0.47143432870486995,\n",
       " 'precision_micro': 0.6116757560733763,\n",
       " 'precision_weighted': 0.8862940958404248,\n",
       " 'recall_macro': 0.7673629633669874,\n",
       " 'recall_micro': 0.6116757560733763,\n",
       " 'recall_weighted': 0.6116757560733763}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_cross_validation(df, 'target', 'gpt4o_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834a6a2-cac5-49a3-b9d9-5e75c9f8410a",
   "metadata": {},
   "source": [
    "# Fine Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72efea6-c1ce-4ab7-a9b9-ef985177e131",
   "metadata": {},
   "source": [
    "#### Important Note\n",
    "At this point in time, only gpt-4o is available for Fine tuning. Thus we'll try to compare the results of a fine tuned newer model of GPT-4 to the base model of gpt-4-turbo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa1301-f1e8-44f2-b005-c907bc601b5c",
   "metadata": {},
   "source": [
    "##### Create the fine tuning file for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7138659-9f57-467c-af58-fbbc999d30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_file_name = 'sales_form_classification_fine_tuning_file'\n",
    "\n",
    "generate_openai_fine_tuning_json_from_df(\n",
    "    fine_tuning_file_name = fine_tuning_file_name, \n",
    "    df = df, \n",
    "    system_prompt = system_prompt, \n",
    "    user_promt_col = 'input_pii_removed', \n",
    "    target_col = 'target', \n",
    "    samples_per_class = 100, \n",
    "    random_state = 12345\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70b4a6-4a17-4d5c-a7f2-f7270f0f2d0e",
   "metadata": {},
   "source": [
    "##### upload file to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d718e0-b242-4f40-b7dc-cbb2c4d550fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-VHKBRDiDpLqFZ9UjgwZGZhzc\n"
     ]
    }
   ],
   "source": [
    "file_id = upload_file_to_openai(f'{fine_tuning_file_name}.jsonl', 'fine-tune')\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47377141-b70a-4a46-840e-d16bb89c8fbe",
   "metadata": {},
   "source": [
    "##### Create the fine tuning job in OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d4a58f-0b67-42a4-9be6-04dc454f5fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-Y9UFGFjh5izTA0aTBf001aVR\n"
     ]
    }
   ],
   "source": [
    "fine_tuning_job_id = fine_tune_gpt_model(\n",
    "    file_id = file_id, \n",
    "    model = 'gpt-4o-2024-08-06',\n",
    "    hyperparameters = {'n_epochs': 20}\n",
    ")\n",
    "print(fine_tuning_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd09cc-ae35-45d9-ae5e-07df155fa66f",
   "metadata": {},
   "source": [
    "##### Check Job Status Until Complete & Get Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caf52860-1d92-4b0e-b317-647eb8592532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJobEvent(id='ftevent-nmzi52txAyFZSi1nDBuRCgqF', created_at=1726828920, level='info', message='Step 1498/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1498, 'train_loss': 6.5394810917496216e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics') \n",
      "\n",
      "\n",
      "FineTuningJobEvent(id='ftevent-eHObMFpzSLxP9cRUHwqPaFIo', created_at=1726828924, level='info', message='Step 1499/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1499, 'train_loss': 1.1444091796875e-05, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics') \n",
      "\n",
      "\n",
      "FineTuningJobEvent(id='ftevent-xhUNZesnSzIFCQwMpAVJQPIc', created_at=1726828940, level='info', message='Step 1500/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1500, 'train_loss': 1.605351826583501e-05, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics') \n",
      "\n",
      "\n",
      "FineTuningJobEvent(id='ftevent-kqh8khtc3zgdKs97GVNmKuFW', created_at=1726828948, level='info', message='Checkpoint created at step 1425', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "FineTuningJobEvent(id='ftevent-WS7kdCI61G9opYjCO4hs7gKu', created_at=1726828948, level='info', message='Checkpoint created at step 1350', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "FineTuningJobEvent(id='ftevent-hVAvEt8qzNUOOX9IlwYHEsG9', created_at=1726828949, level='info', message='New fine-tuned model created', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "FineTuningJobEvent(id='ftevent-XXcOpFCYljNUz1L3wVgEDrz1', created_at=1726828979, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "Fine-tuning job completed successfuly.\n",
      "FineTuningJobEvent(id='ftevent-zGAdrgWzgQyDZdApK9z0T2qJ', created_at=1726828979, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "Fine-tuning job completed successfuly.\n",
      "FineTuningJobEvent(id='ftevent-58aE3s4eOqE5ILqfwDEBwrZw', created_at=1726828979, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "Fine-tuning job completed successfuly.\n",
      "FineTuningJobEvent(id='ftevent-cqjfPm9TbPVVKMXFq291egHy', created_at=1726828980, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message') \n",
      "\n",
      "\n",
      "Fine-tuning job completed successfuly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "job_id = fine_tuning_job_id\n",
    "job_runnig    = True\n",
    "train_loss    = None\n",
    "train_mean_token_accuracy = None\n",
    "attempt = 0\n",
    "\n",
    "while job_runnig:\n",
    "    if attempt > 10:\n",
    "        raise Exception('ERROR: counld NOT get job stopping point!')\n",
    "    else:\n",
    "        job_status_events = check_fine_tuning_job_status(job_id, 10).data\n",
    "        job_status_events = sorted(job_status_events, key=lambda job_status_events: job_status_events.created_at)\n",
    "    \n",
    "        for event in job_status_events:\n",
    "            print(event, '\\n\\n')\n",
    "            # Record model training metrics\n",
    "            if hasattr(event, 'data'):\n",
    "                data = event.data\n",
    "                train_loss = data.get('train_loss')\n",
    "                train_mean_token_accuracy = data.get('train_mean_token_accuracy')\n",
    "    \n",
    "            # Check if the FT job is done\n",
    "            if event.message == \"The job has successfully completed\":\n",
    "                print('Fine-tuning job completed successfuly.')\n",
    "                job_running = False\n",
    "    \n",
    "    if not job_running: break\n",
    "    attempt += 1\n",
    "    time.sleep(60*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c7799-c14e-451b-ae1f-61a122e7b567",
   "metadata": {},
   "source": [
    "##### Get the Fine Tuned models details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "405137f8-f89b-45d3-9e32-8e2f86e74a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tuned Model Name: ft:gpt-4o-2024-08-06:personal::A9VNkczw \n",
      "\n",
      "Fine Tuned Model Name Details:\n",
      "{'created_at': 1726826103,\n",
      " 'error': Error(code=None, message=None, param=None),\n",
      " 'estimated_finish': None,\n",
      " 'fine_tuned_model': 'ft:gpt-4o-2024-08-06:personal::A9VNkczw',\n",
      " 'finished_at': 1726828946,\n",
      " 'hyperparameters': Hyperparameters(n_epochs=20, batch_size=4, learning_rate_multiplier=2),\n",
      " 'id': 'ftjob-Y9UFGFjh5izTA0aTBf001aVR',\n",
      " 'integrations': [],\n",
      " 'model': 'gpt-4o-2024-08-06',\n",
      " 'object': 'fine_tuning.job',\n",
      " 'organization_id': 'org-z3Tqp7IgKTNbmvwBUDk1A5Po',\n",
      " 'result_files': ['file-7jxWG94ZwYc1Ou3YygDOsInA'],\n",
      " 'seed': 85812482,\n",
      " 'status': 'succeeded',\n",
      " 'trained_tokens': 3286640,\n",
      " 'training_file': 'file-VHKBRDiDpLqFZ9UjgwZGZhzc',\n",
      " 'user_provided_suffix': None,\n",
      " 'validation_file': None}\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model_details = get_fine_tuned_model_details(job_id)\n",
    "fine_tuned_model_name = fine_tuned_model_details.fine_tuned_model\n",
    "\n",
    "print(f'Fine Tuned Model Name: {fine_tuned_model_name}', '\\n')\n",
    "print('Fine Tuned Model Name Details:')\n",
    "pprint(fine_tuned_model_details.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea0fb4-4e16-41c6-a312-c9a150e8a318",
   "metadata": {},
   "source": [
    "##### Create test file for batch job in OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17fa71af-c19e-4af5-af22-a2d926ae2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_file_name = 'fine_tune_test_set'\n",
    "\n",
    "batch_data = get_batch_completion_tasks(\n",
    "    df=df,\n",
    "    user_prompt_col='input_pii_removed',\n",
    "    model=fine_tuned_model_name,\n",
    "    temperature=0,\n",
    "    system_prompt=system_prompt,\n",
    "    max_tokens=3\n",
    ")\n",
    "\n",
    "generate_jsonl_file(test_set_file_name, batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b63a84-b43c-4222-bdad-e6744e879f96",
   "metadata": {},
   "source": [
    "##### Upload file to OpenAI for batch completion job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e2dc9ee-9d21-45a7-a5ee-20d24391ca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-6wThQtTVGKBnVsvptuQ7wCy4'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_file_id = upload_file_to_openai(f'{test_set_file_name}.jsonl', 'batch')\n",
    "print(test_set_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045baeac-0d77-405a-8503-daf898b32e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0), _request_id='req_85d231db59a2a1ac48be8ee4db38bf11', __exclude_fields__={'_request_id', '__exclude_fields__'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job = create_batch_completion_job(\n",
    "    test_set_file_id,\n",
    "    \"/v1/chat/completions\",\n",
    "    {\"description\": f\"Get FT model {fine_tuned_model_name} results on test set batch file {test_set_file_id}\"}\n",
    ")\n",
    "batch_job_id = batch_job.id\n",
    "batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69cc3c9d-a4ac-4aa8-8bb3-63d33d18f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=None, in_progress_at=1726912093, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=5341, failed=2657, total=8068), _request_id='req_2bf02405f651f624da0caedb4fded0a8', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=None, in_progress_at=1726912093, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=5341, failed=2657, total=8068), _request_id='req_82469f4e85cdadec64166e9355126633', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=None, in_progress_at=1726912093, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=5341, failed=2657, total=8068), _request_id='req_bdf7acc110dd85e4a10636cdc44875a5', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=1726913708, in_progress_at=1726912093, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=5341, failed=2727, total=8068), _request_id='req_09d257f564aef453df749398c39f571c', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=1726913708, in_progress_at=1726912093, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=5341, failed=2727, total=8068), _request_id='req_3b2dc20a9140062e16e15472e3cd4260', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_d3QuDz8Ietb3s4mWFlNVdZCU', completion_window='24h', created_at=1726912088, endpoint='/v1/chat/completions', input_file_id='file-6wThQtTVGKBnVsvptuQ7wCy4', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726914461, error_file_id='file-KdWv00X8CJIfpLZbVBextrzi', errors=None, expired_at=None, expires_at=1726998488, failed_at=None, finalizing_at=1726913708, in_progress_at=1726912093, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-6wThQtTVGKBnVsvptuQ7wCy4'}, output_file_id='file-qaZk9fL3kbakfOPMD2k2LMtu', request_counts=BatchRequestCounts(completed=5341, failed=2727, total=8068), _request_id='req_d838d68532143e8761368c83ed3df921', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_job_output_file_id = None\n",
    "batch_error_file_id      = None\n",
    "job_status = None\n",
    "\n",
    "while job_status not in ['completed', 'failed', 'cancelled']:\n",
    "    # Check status every 5 minutes\n",
    "    time.sleep(60*5)\n",
    "    \n",
    "    batch_job_status         = get_batch_job_status(batch_job_id)\n",
    "    job_status               = batch_job_status.status\n",
    "    batch_job_output_file_id = batch_job_status.output_file_id\n",
    "    batch_error_file_id      = batch_job_status.error_file_id\n",
    "\n",
    "    print(batch_job_status, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ad2e487-9029-4465-a4fc-040b6bbb14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = get_batch_job_results(batch_job_output_file_id)\n",
    "save_batch_results_to_jsonl(output_file, 'gpt_4o_ft_model_results')\n",
    "\n",
    "df['gpt4_fine_tuned_results'] = None\n",
    "map_jsonl_batch_completion_results_to_df(df, 'gpt_4o_ft_model_results', 'gpt4_fine_tuned_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6319795b-56ad-44d9-ab37-f3921bdc9468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt4_fine_tuned_results\n",
       "sales         3779\n",
       "support       1082\n",
       "irrelevant     479\n",
       "1. support       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gpt4_fine_tuned_results'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29351a20-906b-4279-8a6c-1c0898a65dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_error_file_id:\n",
    "    # Generate Error file for inspection\n",
    "    ft_model_batch_errors = 'gpt_4o_ft_model_erros'\n",
    "    output_file = get_batch_job_results(batch_error_file_id)\n",
    "    save_batch_results_to_jsonl(output_file, ft_model_batch_errors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f06e7418-fe54-4e85-9285-41d9077b0646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-zI8ON2j09af4bYUEi5Kx0AHD\n",
      "Batch(id='batch_sAQ9ecF4xcgXtcDGLYxmeQGR', completion_window='24h', created_at=1726929310, endpoint='/v1/chat/completions', input_file_id='file-zI8ON2j09af4bYUEi5Kx0AHD', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727015710, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-zI8ON2j09af4bYUEi5Kx0AHD'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0), _request_id='req_57587d90cf7e232048d09d6774f128d1', __exclude_fields__={'_request_id', '__exclude_fields__'})\n",
      "Batch(id='batch_sAQ9ecF4xcgXtcDGLYxmeQGR', completion_window='24h', created_at=1726929310, endpoint='/v1/chat/completions', input_file_id='file-zI8ON2j09af4bYUEi5Kx0AHD', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727015710, failed_at=None, finalizing_at=None, in_progress_at=1726929312, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-zI8ON2j09af4bYUEi5Kx0AHD'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2715, failed=11, total=2727), _request_id='req_072250d596ce71c47918b0fc5614385e', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_sAQ9ecF4xcgXtcDGLYxmeQGR', completion_window='24h', created_at=1726929310, endpoint='/v1/chat/completions', input_file_id='file-zI8ON2j09af4bYUEi5Kx0AHD', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727015710, failed_at=None, finalizing_at=None, in_progress_at=1726929312, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-zI8ON2j09af4bYUEi5Kx0AHD'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2715, failed=11, total=2727), _request_id='req_a7bf3fef68c3dcaf1754a46a6a7eef9a', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_sAQ9ecF4xcgXtcDGLYxmeQGR', completion_window='24h', created_at=1726929310, endpoint='/v1/chat/completions', input_file_id='file-zI8ON2j09af4bYUEi5Kx0AHD', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727015710, failed_at=None, finalizing_at=None, in_progress_at=1726929312, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-zI8ON2j09af4bYUEi5Kx0AHD'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2715, failed=11, total=2727), _request_id='req_cb0a6f4801431abfd91f6d2a27a21df4', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_sAQ9ecF4xcgXtcDGLYxmeQGR', completion_window='24h', created_at=1726929310, endpoint='/v1/chat/completions', input_file_id='file-zI8ON2j09af4bYUEi5Kx0AHD', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1727015710, failed_at=None, finalizing_at=1726930445, in_progress_at=1726929312, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-zI8ON2j09af4bYUEi5Kx0AHD'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2716, failed=11, total=2727), _request_id='req_c02e55bd0f0f04aad16a5e0bdb903f55', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n",
      "Batch(id='batch_sAQ9ecF4xcgXtcDGLYxmeQGR', completion_window='24h', created_at=1726929310, endpoint='/v1/chat/completions', input_file_id='file-zI8ON2j09af4bYUEi5Kx0AHD', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726930664, error_file_id='file-N58Zf0m5nNqc83zkGtSnlxJf', errors=None, expired_at=None, expires_at=1727015710, failed_at=None, finalizing_at=1726930445, in_progress_at=1726929312, metadata={'description': 'Get FT model ft:gpt-4o-2024-08-06:personal::A9VNkczw results on test set batch file file-zI8ON2j09af4bYUEi5Kx0AHD'}, output_file_id='file-kkOL586gKQscrxqN6iaAiBlp', request_counts=BatchRequestCounts(completed=2716, failed=11, total=2727), _request_id='req_c2b2154abf505a7d0725a8da0fd01809', __exclude_fields__={'_request_id', '__exclude_fields__'}) \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'map_jsonl_batch_completion_results_to_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m output_file \u001b[38;5;241m=\u001b[39m get_batch_job_results(batch_job_output_file_id)\n\u001b[1;32m     61\u001b[0m save_batch_results_to_jsonl(output_file, err_file_ft_results_name)\n\u001b[0;32m---> 63\u001b[0m map_jsonl_batch_completion_results_to_df(df, err_file_ft_results_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt4_fine_tuned_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'map_jsonl_batch_completion_results_to_df' is not defined"
     ]
    }
   ],
   "source": [
    "### Retry error rows Assuming the errors are 429's (otherwise comment out) ###\n",
    "# Rerun process as many times as needed.\n",
    "\n",
    "# filter all records that need to be retried due to error in batch processing.\n",
    "err_records = set({})\n",
    "\n",
    "with open(f'{ft_model_batch_errors}.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        if row.get('custom_id', False):\n",
    "            err_records.add(int(row['custom_id']))\n",
    "            \n",
    "df_erros = df.loc[df.index.intersection(err_records)]\n",
    "\n",
    "# Create a new batch processing file on the error set\n",
    "err_set_file_name = 'err_fine_tune_test_set'\n",
    "\n",
    "err_batch_data = get_batch_completion_tasks(\n",
    "    df=df_erros,\n",
    "    user_prompt_col='input_pii_removed',\n",
    "    model=fine_tuned_model_name,\n",
    "    temperature=0,\n",
    "    system_prompt=system_prompt,\n",
    "    max_tokens=3\n",
    ")\n",
    "\n",
    "generate_jsonl_file(err_set_file_name, err_batch_data)\n",
    "\n",
    "# Upload error batch set to OpenAI\n",
    "err_test_set_file_id = upload_file_to_openai(f'{err_set_file_name}.jsonl', 'batch')\n",
    "print(err_test_set_file_id)\n",
    "\n",
    "# Create Batch Job for Error File\n",
    "err_batch_job = create_batch_completion_job(\n",
    "    err_test_set_file_id,\n",
    "    \"/v1/chat/completions\",\n",
    "    {\"description\": f\"Get FT model {fine_tuned_model_name} results on test set batch file {err_test_set_file_id}\"}\n",
    ")\n",
    "err_batch_job_id = err_batch_job.id\n",
    "print(err_batch_job)\n",
    "\n",
    "# Monitor Batch job Status\n",
    "batch_job_output_file_id = None\n",
    "batch_error_file_id      = None\n",
    "job_status = None\n",
    "\n",
    "while job_status not in ['completed', 'failed', 'cancelled']:\n",
    "    # Check status every 5 minutes\n",
    "    time.sleep(60*5)\n",
    "    \n",
    "    batch_job_status         = get_batch_job_status(err_batch_job_id)\n",
    "    job_status               = batch_job_status.status\n",
    "    batch_job_output_file_id = batch_job_status.output_file_id\n",
    "    batch_error_file_id      = batch_job_status.error_file_id\n",
    "\n",
    "    print(batch_job_status, '\\n')\n",
    "\n",
    "# Save and map results back to original DF. \n",
    "err_file_ft_results_name = 'gpt_4o_ft_model_results_err_records'\n",
    "output_file = get_batch_job_results(batch_job_output_file_id)\n",
    "save_batch_results_to_jsonl(output_file, err_file_ft_results_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca9c4575-77c5-4cb7-98bb-1712a3988554",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_jsonl_batch_completion_results_to_df(df, err_file_ft_results_name, 'gpt4_fine_tuned_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35c683de-23e4-48d9-b359-1e2ce4f5c371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt4_fine_tuned_results\n",
       "sales         5781\n",
       "support       1643\n",
       "irrelevant     632\n",
       "1. support       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gpt4_fine_tuned_results'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68b9d346-5aeb-4dd3-b6fc-68e54ea288bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_prediction(pred: str) -> str:\n",
    "    valid_preds = set({'sales', 'support', 'irrelevant'})\n",
    "\n",
    "    if not pred or pred in valid_preds: return pred\n",
    "    elif 'sale'       in pred:          return 'sales'\n",
    "    elif 'support'    in pred:          return 'support'    \n",
    "    elif 'irrelevant' in pred:          return 'irrelevant'\n",
    "    else:                               return pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f164d360-042b-4c64-b952-053ffcbbd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gpt4_fine_tuned_results\"] = df[\"gpt4_fine_tuned_results\"].apply(normalize_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcdbbb37-912a-439b-a514-7af303c03f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt4_fine_tuned_results\n",
       "sales         5781\n",
       "support       1644\n",
       "irrelevant     632\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gpt4_fine_tuned_results'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97656266-f4cd-4c08-a07c-6aa6d982156d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7762194365148318,\n",
       " 'f1_macro': 0.5782443612427958,\n",
       " 'f1_micro': 0.7762194365148318,\n",
       " 'f1_weighted': 0.8143054276079603,\n",
       " 'precision_macro': 0.520910951512416,\n",
       " 'precision_micro': 0.7762194365148318,\n",
       " 'precision_weighted': 0.8930905775680181,\n",
       " 'recall_macro': 0.8058122850474941,\n",
       " 'recall_micro': 0.7762194365148318,\n",
       " 'recall_weighted': 0.7762194365148318}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft_results = df[~df['gpt4_fine_tuned_results'].isna()]\n",
    "get_model_cross_validation(df_ft_results,'target', 'gpt4_fine_tuned_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fabb837a-9901-4648-9f89-40d57f33b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sales_inbound_with_gpt_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c694c-43b3-4a43-81a1-4998b0aebf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
